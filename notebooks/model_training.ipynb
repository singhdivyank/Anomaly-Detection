{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Notebook\n",
    "\n",
    "In this notebook, we experiment with various machine learning models on the processed dataset. \n",
    "We perform clustering using K-Means, and we also train classifiers (Random Forest and Neural Network) for anomaly detection.\n",
    "\n",
    "Ensure your processed data file (`smart_meter_data_features.csv`) exists in the data/processed/ directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import functions from modules\n",
    "from src.model_kmeans import perform_kmeans_clustering, evaluate_clustering, plot_clusters\n",
    "from src.model_random_forest import train_random_forest\n",
    "from src.model_neural_network import train_neural_network\n",
    "\n",
    "# Load the processed data\n",
    "data_path = '../data/processed/smart_meter_data_features.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "print('Processed data loaded successfully.')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering Experiment\n",
    "\n",
    "Here we perform K-Means clustering on selected features and evaluate the clustering performance using the silhouette score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for clustering (adjust these based on your dataset)\n",
    "if 'energy_consumption' in data.columns and 'hour' in data.columns:\n",
    "    clustering_features = ['energy_consumption', 'hour']\n",
    "else:\n",
    "    clustering_features = data.columns.tolist()[:2]\n",
    "\n",
    "# Perform clustering\n",
    "data_clustered, kmeans_model = perform_kmeans_clustering(data.copy(), clustering_features, n_clusters=3)\n",
    "\n",
    "# Evaluate clustering performance\n",
    "score = evaluate_clustering(data_clustered, clustering_features)\n",
    "\n",
    "# Visualize the clusters\n",
    "plot_clusters(data_clustered, clustering_features, kmeans_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classification Experiment\n",
    "\n",
    "Next, we train a Random Forest classifier for anomaly detection. Ensure that your dataset includes an 'anomaly' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'anomaly'\n",
    "if target in data.columns:\n",
    "    # Exclude non-feature columns\n",
    "    feature_columns = [col for col in data.columns if col not in ['timestamp', target, 'cluster']]\n",
    "    # Train the Random Forest model\n",
    "    rf_model = train_random_forest(data.copy(), feature_columns, target)\n",
    "else:\n",
    "    print(f\"Column '{target}' not found in data. Skipping Random Forest training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Classification Experiment\n",
    "\n",
    "Now we train a Neural Network model for anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if target in data.columns:\n",
    "    # Use the same feature columns as for Random Forest\n",
    "    feature_columns = [col for col in data.columns if col not in ['timestamp', target, 'cluster']]\n",
    "    # Train the Neural Network (using fewer epochs for demonstration; adjust as needed)\n",
    "    nn_model, history, X_test, y_test, scaler = train_neural_network(data.copy(), feature_columns, target, epochs=20)\n",
    "    \n",
    "    # Plot the training and validation loss\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Neural Network Training Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"Column '{target}' not found in data. Skipping Neural Network training.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
