{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91d81bf6",
   "metadata": {},
   "source": [
    "# Model Training Notebook\n",
    "\n",
    "This notebook demonstrates the process of loading the processed smart meter data (which includes anomaly labels from Isolation Forest) and loading multiple trained models to perform predictions on the data. The following models are loaded:\n",
    "\n",
    "- **Isolation Forest Model**\n",
    "- **LightGBM Model**\n",
    "- **Neural Network Model** (along with its scaler)\n",
    "\n",
    "The notebook also shows simple prediction examples for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c914d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6caac3",
   "metadata": {},
   "source": [
    "## Define File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227d3b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for data and models\n",
    "data_path = \"data/processed/smart_meter_data_anomalies_if.csv\"\n",
    "if_model_path = \"models/isolation_forest_model.pkl\"\n",
    "lgbm_model_path = \"models/lightgbm_model.pkl\"\n",
    "nn_model_path = \"models/nn_model.h5\"\n",
    "nn_scaler_path = \"models/nn_scaler.pkl\"\n",
    "\n",
    "print(\"Data path:\", data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0c0d5e",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac764fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Attempting to load data from: {data_path}\")\n",
    "try:\n",
    "    # Uncomment and adjust nrows if you need a smaller sample for demonstration\n",
    "    # data = pd.read_csv(data_path, nrows=100000)\n",
    "    data = pd.read_csv(data_path)\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Data file not found at {data_path}.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aae8566",
   "metadata": {},
   "source": [
    "## Determine Feature Columns\n",
    "\n",
    "We select all numeric columns (excluding a few that are not features) to form our feature set. The target is defined as `anomaly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aee575",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDetermining feature columns...\")\n",
    "numeric_features = data.select_dtypes(include=np.number).columns.tolist()\n",
    "# Exclude non-feature columns\n",
    "features_to_exclude = ['cluster', 'anomaly_score', 'anomaly', 'LCLid']\n",
    "features = [col for col in numeric_features if col not in features_to_exclude]\n",
    "target = 'anomaly'\n",
    "\n",
    "if target not in data.columns:\n",
    "    print(f\"Target column '{target}' not found in data.\")\n",
    "    exit()\n",
    "if not features:\n",
    "    print(\"Could not determine feature columns.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Using features:\", features)\n",
    "X = data[features]\n",
    "y = data[target]  # Not used for prediction demonstration, but defined for consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ffd5d4",
   "metadata": {},
   "source": [
    "## Load Isolation Forest Model and Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d755db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nAttempting to load Isolation Forest model from: {if_model_path}\")\n",
    "if os.path.exists(if_model_path):\n",
    "    try:\n",
    "        if_model = joblib.load(if_model_path)\n",
    "        print(\"Isolation Forest model loaded successfully.\")\n",
    "        # Example: Get anomaly scores for the first 5 rows\n",
    "        print(\"Isolation Forest anomaly scores (first 5):\")\n",
    "        print(if_model.decision_function(X.head()))\n",
    "        print(\"-\" * 30)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Isolation Forest model: {e}\")\n",
    "else:\n",
    "    print(f\"Isolation Forest model file not found at {if_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21933738",
   "metadata": {},
   "source": [
    "## Load LightGBM Model and Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb3ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nAttempting to load LightGBM model from: {lgbm_model_path}\")\n",
    "if os.path.exists(lgbm_model_path):\n",
    "    try:\n",
    "        lgbm_model = joblib.load(lgbm_model_path)\n",
    "        print(\"LightGBM model loaded successfully.\")\n",
    "        # Example: Predict probabilities for the first 5 rows\n",
    "        print(\"LightGBM predicted probabilities (first 5):\")\n",
    "        print(lgbm_model.predict_proba(X.head()))\n",
    "        print(\"-\" * 30)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading LightGBM model: {e}\")\n",
    "else:\n",
    "    print(f\"LightGBM model file not found at {lgbm_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be1ccef",
   "metadata": {},
   "source": [
    "## Load Neural Network Model and Scaler, Then Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de94b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nAttempting to load Neural Network model from: {nn_model_path}\")\n",
    "print(f\"Attempting to load Neural Network scaler from: {nn_scaler_path}\")\n",
    "if os.path.exists(nn_model_path) and os.path.exists(nn_scaler_path):\n",
    "    try:\n",
    "        nn_model = tf.keras.models.load_model(nn_model_path)\n",
    "        scaler = joblib.load(nn_scaler_path)\n",
    "        print(\"Neural Network model and scaler loaded successfully.\")\n",
    "        \n",
    "        # Scale the features before prediction\n",
    "        X_scaled = scaler.transform(X.head())\n",
    "        # Example: Predict probabilities for the first 5 rows\n",
    "        print(\"Neural Network predicted probabilities (first 5):\")\n",
    "        print(nn_model.predict(X_scaled))\n",
    "        print(\"-\" * 30)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Neural Network model or scaler: {e}\")\n",
    "else:\n",
    "    if not os.path.exists(nn_model_path):\n",
    "        print(f\"Neural Network model file not found at {nn_model_path}\")\n",
    "    if not os.path.exists(nn_scaler_path):\n",
    "        print(f\"Neural Network scaler file not found at {nn_scaler_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2940692d",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16836a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nModel loading and prediction demonstration finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
