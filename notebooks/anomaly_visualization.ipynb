{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fb813e3",
   "metadata": {},
   "source": [
    "# Anomaly Visualization Notebook\n",
    "\n",
    "This notebook visualizes the anomalies in the smart meter data using the Isolation Forest method as well as displays predictions from other supervised models (LightGBM and a Neural Network). It includes:\n",
    "\n",
    "- Isolation Forest anomaly visualization on a selected time window\n",
    "- Distribution of anomaly scores\n",
    "- Scatter plot of anomaly scores vs. energy consumption\n",
    "- Optional supervised model prediction visualizations (LGBM and NN predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a627179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7924a95",
   "metadata": {},
   "source": [
    "## Configuration and Data Loading\n",
    "\n",
    "The following cell sets up file paths and loads the data. It also ensures that the `DateTime` column is parsed and the data is sorted by time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b1f13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "data_path = 'data/processed/smart_meter_data_anomalies_if.csv'\n",
    "if_model_path = \"models/isolation_forest_model.pkl\"\n",
    "# Add paths for other models if you want to visualize their predictions\n",
    "lgbm_model_path = \"models/lightgbm_model.pkl\"\n",
    "nn_model_path = \"models/nn_model.h5\"\n",
    "nn_scaler_path = \"models/nn_scaler.pkl\"\n",
    "\n",
    "print(f\"Attempting to load data from: {data_path}\")\n",
    "try:\n",
    "    # You may uncomment the nrows parameter for a smaller sample if needed\n",
    "    # data = pd.read_csv(data_path, nrows=500000)\n",
    "    data = pd.read_csv(data_path)\n",
    "    print(\"Data loaded successfully.\")\n",
    "    # Ensure DateTime is parsed and sorted\n",
    "    if 'DateTime' in data.columns:\n",
    "        data['DateTime'] = pd.to_datetime(data['DateTime'])\n",
    "        data.sort_values('DateTime', inplace=True)\n",
    "    else:\n",
    "        print(\"Warning: DateTime column not found.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Data file not found at {data_path}.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d13ec3d",
   "metadata": {},
   "source": [
    "## Visualizing Isolation Forest Anomalies\n",
    "\n",
    "This cell selects a shorter time window from the data (e.g., a 30-day period starting 90 days into the dataset) and then plots the overall energy consumption alongside the anomalies detected by Isolation Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfa7c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'anomaly' in data.columns and 'DateTime' in data.columns and 'KWH/hh (per half hour)' in data.columns:\n",
    "    print(\"\\nVisualizing Isolation Forest Anomalies...\")\n",
    "    \n",
    "    # Select a shorter time window for clarity (e.g., one month)\n",
    "    start_date = data['DateTime'].min() + pd.Timedelta(days=90)  # Example: Start 90 days in\n",
    "    end_date = start_date + pd.Timedelta(days=30)  # Plot 30 days\n",
    "    mask = (data['DateTime'] >= start_date) & (data['DateTime'] <= end_date)\n",
    "    subset = data.loc[mask]\n",
    "\n",
    "    if not subset.empty:\n",
    "        plt.figure(figsize=(15, 7))\n",
    "        # Plot overall energy consumption for the subset\n",
    "        plt.plot(subset['DateTime'], subset['KWH/hh (per half hour)'], color='lightgray', \n",
    "                 label='Energy Consumption', alpha=0.7)\n",
    "        \n",
    "        # Highlight anomalies detected by Isolation Forest\n",
    "        anomalies_subset = subset[subset['anomaly'] == 1]\n",
    "        plt.scatter(anomalies_subset['DateTime'], anomalies_subset['KWH/hh (per half hour)'],\n",
    "                    color='red', label='IF Anomaly (1)', marker='o', s=10)  # Smaller markers\n",
    "        \n",
    "        plt.xlabel('Timestamp')\n",
    "        plt.ylabel('Energy Consumption (kWh per half hour)')\n",
    "        plt.title(f'Energy Consumption with Isolation Forest Anomalies ({start_date.date()} to {end_date.date()})')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No data found in the selected time window for anomaly visualization.\")\n",
    "elif 'anomaly' not in data.columns:\n",
    "    print(\"Column 'anomaly' not found. Cannot visualize anomalies.\")\n",
    "else:\n",
    "    print(\"Required columns ('DateTime', 'KWH/hh (per half hour)') not found for anomaly time series plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3708eeb0",
   "metadata": {},
   "source": [
    "## Visualizing Anomaly Scores\n",
    "\n",
    "This cell shows the distribution of anomaly scores computed by the Isolation Forest method, along with a scatter plot of anomaly score vs. energy consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3178cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'anomaly_score' in data.columns:\n",
    "    print(\"\\nVisualizing Anomaly Score Distribution...\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data['anomaly_score'], bins=50, kde=True)\n",
    "    plt.title('Distribution of Isolation Forest Anomaly Scores')\n",
    "    plt.xlabel('Anomaly Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "    \n",
    "    # Scatter plot of score vs consumption (use sample to avoid overplotting)\n",
    "    if 'KWH/hh (per half hour)' in data.columns:\n",
    "         plt.figure(figsize=(10, 6))\n",
    "         sample_df = data.sample(n=min(50000, len(data)), random_state=42)\n",
    "         plt.scatter(sample_df['KWH/hh (per half hour)'], sample_df['anomaly_score'],\n",
    "                     c=sample_df['anomaly'], cmap='coolwarm', alpha=0.5, s=5)\n",
    "         plt.xlabel('Energy Consumption (kWh per half hour)')\n",
    "         plt.ylabel('Anomaly Score')\n",
    "         plt.title('Anomaly Score vs. Energy Consumption')\n",
    "         plt.colorbar(label='Anomaly (1=Anomaly, 0=Normal)')\n",
    "         plt.show()\n",
    "else:\n",
    "    print(\"Column 'anomaly_score' not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8852d9",
   "metadata": {},
   "source": [
    "## Optional: Visualizing Supervised Model Predictions\n",
    "\n",
    "The following section demonstrates how to visualize predictions from supervised models. We first define the features to use (excluding certain columns) and then attempt to load models to predict on the data.\n",
    "\n",
    "### LightGBM Prediction Visualization\n",
    "A crosstab of Isolation Forest anomaly labels versus LightGBM predictions is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c00efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features consistently (should match training)\n",
    "numeric_features = data.select_dtypes(include=np.number).columns.tolist()\n",
    "features_to_exclude = ['cluster', 'anomaly_score', 'anomaly', 'LCLid']\n",
    "features = [col for col in numeric_features if col not in features_to_exclude]\n",
    "\n",
    "if features:\n",
    "    print(\"\\nVisualizing LGBM Predictions (Example)...\")\n",
    "    if os.path.exists(lgbm_model_path):\n",
    "        try:\n",
    "            lgbm_model = joblib.load(lgbm_model_path)\n",
    "            data['lgbm_prediction'] = lgbm_model.predict(data[features])\n",
    "            print(\"\\nComparison of IF Anomaly vs LGBM Prediction (Counts):\")\n",
    "            print(pd.crosstab(data['anomaly'], data['lgbm_prediction'], rownames=['IF Anomaly'], colnames=['LGBM Prediction']))\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading or predicting with LGBM model: {e}\")\n",
    "    else:\n",
    "         print(f\"LGBM model not found at {lgbm_model_path}, skipping visualization.\")\n",
    "else:\n",
    "    print(\"Could not determine features for supervised model prediction visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ff6fb3",
   "metadata": {},
   "source": [
    "### Neural Network Prediction Visualization\n",
    "\n",
    "This cell loads the Neural Network model and its scaler, scales the features, and then predicts probabilities. A crosstab comparing Isolation Forest anomaly labels with NN predictions is displayed. Additionally, if a time subset exists, prediction disagreements are highlighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3090c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nVisualizing Neural Network Predictions...\")\n",
    "if os.path.exists(nn_model_path) and os.path.exists(nn_scaler_path):\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        nn_model = tf.keras.models.load_model(nn_model_path)\n",
    "        scaler = joblib.load(nn_scaler_path)\n",
    "        print(\"NN model and scaler loaded.\")\n",
    "\n",
    "        # Scale features for prediction\n",
    "        X_scaled = scaler.transform(data[features])\n",
    "        nn_probabilities = nn_model.predict(X_scaled)\n",
    "        threshold = 0.5\n",
    "        data['nn_prediction'] = (nn_probabilities > threshold).astype(int)\n",
    "\n",
    "        print(\"\\nComparison of IF Anomaly vs NN Prediction (Counts):\")\n",
    "        print(pd.crosstab(data['anomaly'], data['nn_prediction'], rownames=['IF Anomaly'], colnames=['NN Prediction']))\n",
    "\n",
    "        # Optional: If a time subset was defined in the Isolation Forest section, visualize disagreements\n",
    "        if 'subset' in locals() and not subset.empty:\n",
    "             try:\n",
    "                 subset_scaled = scaler.transform(subset[features])\n",
    "                 subset['nn_prediction'] = (nn_model.predict(subset_scaled) > threshold).astype(int)\n",
    "                 mismatches = subset[subset['anomaly'] != subset['nn_prediction']]\n",
    "                 if not mismatches.empty:\n",
    "                     plt.figure(figsize=(15, 7))\n",
    "                     plt.plot(subset['DateTime'], subset['KWH/hh (per half hour)'], \n",
    "                              color='lightgray', label='Energy Consumption', alpha=0.7)\n",
    "                     plt.scatter(mismatches['DateTime'], mismatches['KWH/hh (per half hour)'],\n",
    "                                 color='purple', label='IF/NN Disagreement', marker='x', s=20)\n",
    "                     plt.title(f'IF/NN Prediction Disagreements ({subset[\"DateTime\"].min().date()} to {subset[\"DateTime\"].max().date()})')\n",
    "                     plt.legend()\n",
    "                     plt.show()\n",
    "                 else:\n",
    "                     print(\"No disagreements found between IF and NN predictions in the subset.\")\n",
    "             except Exception as e:\n",
    "                 print(f\"Error during NN prediction visualization on subset: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or predicting with NN model: {e}\")\n",
    "else:\n",
    "    if not os.path.exists(nn_model_path):\n",
    "        print(f\"NN model file not found at {nn_model_path}, skipping visualization.\")\n",
    "    if not os.path.exists(nn_scaler_path):\n",
    "        print(f\"NN scaler file not found at {nn_scaler_path}, skipping visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62988d9a",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The anomaly visualization notebook has now demonstrated several key visualizations, including isolation forest anomalies, anomaly score distributions, and supervised model prediction comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de79e2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAnomaly visualization script finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
